#+TITLE: Publication Modes Favoring Reproducible Research

Nicolas Rougier is late but he should hopefully arrive any time soon.

* Notes taken during the Introduction by Kondrad
- Interest of publications: in physics, the timespan is around decades. It happens to cite work that was made centuries ago but it's moslty for historical reasons. In such cases, one rather refers to textbooks.
- Active papers: HDF5 allows to type objects and to distinguish between data sets, calclets that are meant to be run and isolated from the rest of the world, doi that should be downloaded, local references (that prevent reproducibility by other persons), dummy data sets that can be recomputed
- An AP can be used as an external library.
- ReScience: replicating the work of someone else is actually a very good exercise for a master student. It shows you're able to read a paper, understand, and conduct similar work.


* Questions on the Introduction:
** Software Decay ?
** How much level of detail about the software actually matters?
    - Every detail matters, except proven the contrary.
** Can you tell us more about transitive credit ?
   - Each author state the importance of each library contribution to its own work.
** Code Ocean ? Why does it look interesting to you ?
   - Platform to install its own code, add user interface (like a docker container publicly available) \to embed in a webpage
   - Free ? Sustainable ?
** Statcheck takes a pdf as an input ? How can that work ? What is the scope ? Mostly tracking obvious problems ?
   - Specific markup embedded in the PDF for a field of science (psychology)
* Questions on ActivePapers
** Can you do versioning (git) for an AP (inside the HDF5 blob)? Related question: how do you keep track of "old" results ?
   - Currently not.  Old results are not kept.
** So AP looks like a mixture of container/workflow/tar archive. You showed us how to exploit it but what is the "cost" of using it on a daily basis ?
    - What I meant is how do you express dependancies ? How do you get to a working ActivePaper ?
      - Dependencies are generated by running the intiialziation AP script 
    - You said the large data sets were not published but you copied important information. What does that mean ? How did you express this ?
        - Actually, all this is expressed "manually". There is a shell script that put data , code, etc. in the HDF5.
** Dependency problem: you said you had a problem with matplotlib but I thought AP was keeping track of dependancies... Why don't you use a frozen version number for matplotlib?
    - You have to declare external dependancies. If you don't , it wont work.
** isn't there a way through github, pip, or conda to retrieve older versions from matplotlib?
** What about Nix ? Could it be mixed and used to solve some of the shortcomings ?
* Questions on Rescience
** So, in the introductory example, it was good that the code was so obscure, this pushed to replicate, otherwise, you would just have used the model, right?
** What features of Github are you using ? What about gitlab ? It also supports the fork/pull model, right ?
** Open submission/review model.
*** Is there a policy regarding the choice of the reviewers ?
     - Even the original author could be a reviewer but it does not happen.
     - Open review tend to make stupid/mean/ ... reviews and CoI disappear anyway.
*** Anonymous publications ?
     - The easiest solution is to create a fake id/login and possibly reveal your identity later.
*** Open reviews often scare people. There are other experience with reddit/artifact evaluation. Your opinion so far is it's great ?
*** Do you reject replications in ReScience?
** Markdown format seems like the only requirement. So there is nothing related to litterate programming, enforcing workflows, etc. How difficult is it to check the replicated work is correct ?
** Reviewing delay ?
    - 3-4 months
** ReScience^X in collaboration with osf ? You mentioned psychology. How does the checking of the experimental part work ? Would experimental computer science make sense ?
** To ensure replicability of the replication, ask the reviewer to run it on a fresh Linux VM ?
